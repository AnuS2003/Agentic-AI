# ðŸ§  Agentic AI Research Assistant

A lightweight, fast, and local agentic AI that can:
- Rewrite prompts for better understanding
- Plan subtasks when queries are complex
- Query multiple local LLMs (like `tinyllama`, `phi3`)
- Rank and evaluate responses using semantic similarity
- Self-improve based on critique
- Show alternative answers on demand

Built with:
- [Ollama](https://ollama.com/) for running local LLMs
- `sentence-transformers` for semantic ranking
- `concurrent.futures` for fast parallel model querying

---

## ðŸš€ Features

| Feature         | Description |
|----------------|-------------|
| ðŸ” Prompt Rewriting | Improves vague or unclear input |
| ðŸ” Subtask Planning | Breaks down complex queries |
| ðŸ¤– Multi-LLM Querying | Runs queries through multiple local models |
| ðŸ§  Semantic Ranking | Uses embeddings to rank responses |
| ðŸ“‹ Critique + Improve | LLM evaluates and improves its own response |
| ðŸ“š Show More | Allows viewing responses from other models |

---

## ðŸ§° Requirements

- Python 3.8+
- [`Ollama`](https://ollama.com/) installed and running
- Required Python packages:
  
## Workflow
  [USER] --> Rewrite --> Plan Subtasks --> Query LLMs --> Rank --> Critique --> Improve or [Show more] --> [Final Answer]


